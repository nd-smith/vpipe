# =============================================================================
# Kafka Pipeline Environment Configuration - EXAMPLE
# Copy this file to .env and fill in your actual values
# =============================================================================

# =============================================================================
# ENVIRONMENT & PLATFORM
# =============================================================================
# Pipeline domain: xact or claimx (default: xact)
# PIPELINE_DOMAIN=xact

# Environment type: development, staging, production (affects security checks)
# ENVIRONMENT=development

# Deployment environment indicator (used for production detection)
# DEPLOYMENT_ENV=

# Application environment indicator (used for production detection)
# APP_ENV=

# Event source type: eventhub or eventhouse (default: eventhub)
# EVENT_SOURCE=eventhouse

# =============================================================================
# AZURE AUTHENTICATION
# =============================================================================
# Priority chain: Token file > Cached token > Service Principal (SPN)

# Path to token file containing Azure access tokens (alternative to SPN)
# AZURE_TOKEN_FILE=

# Azure Service Principal authentication (for OAuth to Azure services)
# Uncomment and set these if using Service Principal authentication:
# AZURE_TENANT_ID=00000000-0000-0000-0000-000000000000
# AZURE_CLIENT_ID=00000000-0000-0000-0000-000000000000
# AZURE_CLIENT_SECRET=your-client-secret-here

# Enable interactive Azure CLI authentication (default: false)
# AZURE_AUTH_INTERACTIVE=false

# =============================================================================
# AZURE ONELAKE / FABRIC
# =============================================================================
# Azure OneLake workspace and lakehouse identifiers
AZURE_WORKSPACE_ID=00000000-0000-0000-0000-000000000000
AZURE_LAKEHOUSE_ID=00000000-0000-0000-0000-000000000000

# OneLake base path template
# Format: abfss://{WORKSPACE_ID}@onelake.dfs.fabric.microsoft.com/{LAKEHOUSE_ID}/Files/veriskPipeline
ONELAKE_BASE_PATH=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Files/veriskPipeline

# Domain-specific OneLake paths (optional, defaults to ONELAKE_BASE_PATH)
# ONELAKE_XACT_PATH=
# ONELAKE_CLAIMX_PATH=

# =============================================================================
# EVENTHOUSE - CORE SETTINGS
# =============================================================================
# Eventhouse cluster URL (shared across domains)
EVENTHOUSE_CLUSTER_URL=https://your-cluster.kusto.fabric.microsoft.com

# Query timeout in seconds (default: 120)
# EVENTHOUSE_QUERY_TIMEOUT=120

# Maximum number of retries for queries (default: 3)
# EVENTHOUSE_MAX_RETRIES=3

# Base retry delay in seconds (default: 1)
# EVENTHOUSE_RETRY_BASE_DELAY=1

# Maximum retry delay in seconds (default: 60)
# EVENTHOUSE_RETRY_MAX_DELAY=60

# Proxy URL for Eventhouse connections (optional)
# EVENTHOUSE_PROXY_URL=
# HTTP_PROXY=
# HTTPS_PROXY=

# Generic Eventhouse database name (used if domain-specific not set)
# EVENTHOUSE_DATABASE=

# =============================================================================
# EVENTHOUSE - XACT DOMAIN
# =============================================================================
# XACT Eventhouse settings
XACT_EVENTHOUSE_DATABASE=YOUR_XACT_DATABASE
XACT_EVENTHOUSE_SOURCE_TABLE=tbl_XACT_EVENTS

# XACT Eventhouse cluster URL (fallback to EVENTHOUSE_CLUSTER_URL if not set)
# XACT_EVENTHOUSE_CLUSTER_URL=

# XACT polling configuration
# POLL_INTERVAL_SECONDS=30              # How often to poll Eventhouse (default: 30)
# POLL_BATCH_SIZE=1000                  # Events to fetch per poll (default: 1000)

# XACT deduplication configuration
# XACT_EVENTS_WINDOW_HOURS=24           # Dedup window in hours (default: 24)
# DEDUP_EVENTHOUSE_WINDOW_HOURS=1       # Eventhouse query window (default: 1)
# DEDUP_OVERLAP_MINUTES=5               # Query overlap to prevent gaps (default: 5)

# XACT backfill configuration
# DEDUP_BACKFILL_START_TIMESTAMP=       # ISO 8601 timestamp to start backfill
# DEDUP_BACKFILL_STOP_TIMESTAMP=        # ISO 8601 timestamp to stop backfill
# DEDUP_BULK_BACKFILL=false             # Enable bulk backfill mode (default: false)
# DEDUP_KQL_START_TIMESTAMP=            # KQL start timestamp for real-time mode

# Path to xact_events Delta table (for dedup checking)
# XACT_EVENTS_TABLE_PATH=

# =============================================================================
# EVENTHOUSE - CLAIMX DOMAIN
# =============================================================================
# ClaimX Eventhouse settings
CLAIMX_EVENTHOUSE_DATABASE=YOUR_CLAIMX_DATABASE
CLAIMX_EVENTHOUSE_SOURCE_TABLE=tbl_CLAIMX_EVENTS

# ClaimX Eventhouse cluster URL (fallback to EVENTHOUSE_CLUSTER_URL if not set)
# CLAIMX_EVENTHOUSE_CLUSTER_URL=

# ClaimX polling configuration
# CLAIMX_POLL_INTERVAL_SECONDS=30       # How often to poll Eventhouse (default: 30)
# CLAIMX_POLL_BATCH_SIZE=1000           # Events to fetch per poll (default: 1000)
# CLAIMX_EVENTHOUSE_QUERY_TIMEOUT=120   # Query timeout in seconds (default: 120)

# ClaimX deduplication configuration
# CLAIMX_DEDUP_EVENTS_WINDOW_HOURS=24   # Dedup window in hours (default: 24)
# CLAIMX_DEDUP_EVENTHOUSE_WINDOW_HOURS=1 # Eventhouse query window (default: 1)
# CLAIMX_DEDUP_OVERLAP_MINUTES=5        # Query overlap to prevent gaps (default: 5)

# ClaimX backfill configuration
# CLAIMX_DEDUP_BACKFILL_START_TIMESTAMP= # ISO 8601 timestamp to start backfill
# CLAIMX_DEDUP_BACKFILL_STOP_TIMESTAMP=  # ISO 8601 timestamp to stop backfill
# CLAIMX_DEDUP_BULK_BACKFILL=false      # Enable bulk backfill mode (default: false)
# CLAIMX_DEDUP_KQL_START_TIMESTAMP=     # KQL start timestamp for real-time mode

# Path to claimx_events Delta table (for dedup checking)
# CLAIMX_EVENTS_TABLE_PATH=

# ClaimX Kafka topic for events (default: com.allstate.pcesdopodappv1.claimx.events.raw)
# CLAIMX_EVENTS_TOPIC=com.allstate.pcesdopodappv1.claimx.events.raw

# =============================================================================
# DELTA LAKE TABLE PATHS - XACT
# =============================================================================
XACT_DELTA_EVENTS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/xact_events
XACT_DELTA_INVENTORY_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/xact_attachments

# Alternative names for XACT Delta tables (mapped to same tables)
# DELTA_EVENTS_TABLE_PATH=              # Alternative to XACT_DELTA_EVENTS_TABLE
# DELTA_INVENTORY_TABLE_PATH=           # Alternative to XACT_DELTA_INVENTORY_TABLE

# XACT permanent failures table
# DELTA_FAILED_TABLE_PATH=

# =============================================================================
# DELTA LAKE TABLE PATHS - CLAIMX
# =============================================================================
CLAIMX_DELTA_EVENTS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_events
CLAIMX_DELTA_INVENTORY_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_attachments
CLAIMX_DELTA_PROJECTS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_projects
CLAIMX_DELTA_CONTACTS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_contacts
CLAIMX_DELTA_MEDIA_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_attachments_metadata
CLAIMX_DELTA_TASKS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_tasks
CLAIMX_DELTA_TASK_TEMPLATES_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_task_templates
CLAIMX_DELTA_EXTERNAL_LINKS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_external_link
CLAIMX_DELTA_VIDEO_COLLAB_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_video_collab

# =============================================================================
# DELTA LAKE - GENERAL SETTINGS
# =============================================================================
# Enable Delta Lake writes (default: true)
# ENABLE_DELTA_WRITES=true

# Events per Delta batch (default: 1000)
# DELTA_EVENTS_BATCH_SIZE=1000

# =============================================================================
# EVENT HUB NAMESPACE CONNECTION
# =============================================================================
# Namespace-level connection string (NO EntityPath).
# One secret manages access to ALL Event Hubs in the namespace.
# Entity names and consumer groups are defined per-topic in config.yaml.
#
# Format: Endpoint=sb://namespace.servicebus.windows.net/;SharedAccessKeyName=...;SharedAccessKey=...
# NOTE: Do NOT include EntityPath — it is resolved per-topic from config.yaml.
EVENTHUB_NAMESPACE_CONNECTION_STRING=Endpoint=sb://your-namespace.servicebus.windows.net/;SharedAccessKeyName=YourKeyName;SharedAccessKey=YourKeyValue

# Default consumer group (used when not specified per-topic in config.yaml)
# EVENTHUB_DEFAULT_CONSUMER_GROUP=$Default

# Event Hub Kafka-compatible bootstrap servers (legacy, for Kafka protocol fallback)
# EVENTHUB_BOOTSTRAP_SERVERS=

# Auto offset reset strategy: earliest, latest, none (default: earliest)
# EVENTHUB_AUTO_OFFSET_RESET=earliest

# =============================================================================
# KAFKA CONFIGURATION - INTERNAL PIPELINE
# =============================================================================
# Primary Kafka broker addresses
# Format: comma-separated host:port list. Port depends on security protocol:
#   SASL_PLAINTEXT -> 9092 | SASL_SSL -> 9093 | SSL (mTLS) -> 9094
#
# Corporate Kafka cluster (SASL_SSL):
KAFKA_BOOTSTRAP_SERVERS=lxv102325.company.com:9093,lxv102326.company.com:9093,lxv102327.company.com:9093,lxv102328.company.com:9093,lxv102329.company.com:9093,lxv102330.company.com:9093,lxv102331.company.com:9093,lxv102332.company.com:9093
KAFKA_SECURITY_PROTOCOL=SASL_SSL

# SASL mechanism: GSSAPI (Kerberos), PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER
KAFKA_SASL_MECHANISM=GSSAPI

# Kerberos service name (must match broker's service principal, default: kafka)
# KAFKA_SASL_KERBEROS_SERVICE_NAME=kafka

# Schema Registry URL
KAFKA_SCHEMA_REGISTRY_URL=https://rtvdevro-kafka.tptigslb.company.com:8081

# Local Kafka configuration (for internal pipeline communication)
# LOCAL_KAFKA_BOOTSTRAP_SERVERS=localhost:9094
# LOCAL_KAFKA_SECURITY_PROTOCOL=PLAINTEXT
# LOCAL_KAFKA_SASL_MECHANISM=
# LOCAL_KAFKA_SASL_USERNAME=
# LOCAL_KAFKA_SASL_PASSWORD=

# Consumer group prefix for all consumers
# KAFKA_CONSUMER_GROUP_PREFIX=

# =============================================================================
# KAFKA TOPICS
# =============================================================================
# Main event topics
# KAFKA_EVENTS_TOPIC=                   # Raw events topic
# KAFKA_EVENTS_INGESTED_TOPIC=          # Ingested events topic

# Download workflow topics
# KAFKA_DOWNLOADS_PENDING_TOPIC=        # Downloads pending processing
# KAFKA_DOWNLOADS_CACHED_TOPIC=         # Downloads cached locally
# KAFKA_DOWNLOADS_RESULTS_TOPIC=        # Download results

# Dead letter queue for failed messages
# KAFKA_DLQ_TOPIC=

# =============================================================================
# CLAIMX API
# =============================================================================
# ClaimX API base URL
CLAIMX_API_BASE_PATH=https://www.claimxperience.com/service/cxedirest

# Alternative base URL variable (CLAIMX_API_BASE_PATH takes precedence)
# CLAIMX_API_URL=https://www.claimxperience.com/service/cxedirest

# ClaimX API authentication (use token OR username/password)
CLAIMX_API_TOKEN=base64-encoded-token-here
CLAIMX_API_USERNAME=
CLAIMX_API_PASSWORD=

# ClaimX API operational settings
# CLAIMX_API_TIMEOUT_SECONDS=30         # Request timeout (default: 30)
# CLAIMX_API_CONCURRENCY=20             # Max concurrent requests (default: 20)

# =============================================================================
# RATE LIMITING
# =============================================================================
# ClaimX API rate limiting
# CLAIMX_API_RATE_LIMIT_ENABLED=false   # Enable rate limiting (default: false)
# CLAIMX_API_RATE_LIMIT_PER_SECOND=10   # Calls per second (default: 10)

# External download rate limiting
# EXTERNAL_DOWNLOAD_RATE_LIMIT_ENABLED=false # Enable rate limiting (default: false)
# EXTERNAL_DOWNLOAD_RATE_LIMIT_PER_SECOND=10 # Downloads per second (default: 10)

# =============================================================================
# STORAGE & CACHING
# =============================================================================
# Local cache directory for downloaded files
CACHE_DIR=/tmp/kafka_pipeline_cache

# =============================================================================
# SECURITY & URL VALIDATION
# =============================================================================
# Comma-separated list of allowed domains for attachment downloads
# Example: ALLOWED_ATTACHMENT_DOMAINS=claimxperience.com,example.com,*.azure.com
# ALLOWED_ATTACHMENT_DOMAINS=

# Note: Localhost and private IP ranges are blocked in production environments
# Production is detected via ENVIRONMENT, DEPLOYMENT_ENV, or APP_ENV variables

# Disable SSL certificate verification for local development behind corporate
# proxies that intercept TLS with self-signed certificates.
# WARNING: Never enable in production — the module refuses if ENVIRONMENT=production.
# DISABLE_SSL_VERIFY=false

# =============================================================================
# LOGGING & MONITORING
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL (default: INFO)
LOG_LEVEL=INFO

# Log directory (default: logs)
# LOG_DIR=logs

# Use JSON log format for structured logging (default: true)
# JSON_LOGS=true

# Send all log output to stdout only, skipping file handlers (default: false)
# Useful for containerized deployments where logs are captured from stdout.
# Can also be set via --log-to-stdout CLI flag.
# LOG_TO_STDOUT=false

# OneLake log upload configuration (Cloud Foundry deployments)
# Enable automatic upload of rotated logs to OneLake (default: false)
# LOG_UPLOAD_ENABLED=false

# Maximum log file size in MB before rotation (default: 50)
# LOG_MAX_SIZE_MB=50

# Time-based rotation interval in minutes (default: 15)
# LOG_ROTATION_MINUTES=15

# Local log retention in hours (logs older than this are deleted) (default: 2)
# LOG_RETENTION_HOURS=2

# OneLake path for log uploads (default: {ONELAKE_BASE_PATH}/logs)
# ONELAKE_LOG_PATH=abfss://workspace@onelake.dfs.fabric.microsoft.com/lakehouse/Files/logs

# Worker identifier for multi-worker logging
# WORKER_ID=

# Enable telemetry collection (default: true)
# ENABLE_TELEMETRY=true

# Retry configuration
# RETRY_DELAYS=1,2,5,10                 # Comma-separated retry delays in seconds
# MAX_RETRIES=3                         # Maximum number of retries

# =============================================================================
# OUTPUT & TESTING
# =============================================================================
# JSON output configuration (for testing/debugging)
# JSON_OUTPUT_PATH=output/xact_events.jsonl # Output file path
# JSON_ROTATE_SIZE_MB=100               # File rotation size in MB (default: 100)
# JSON_PRETTY_PRINT=false               # Pretty print JSON (default: false)
# JSON_INCLUDE_METADATA=true            # Include metadata in output (default: true)

# =============================================================================
# SIMULATION MODE
# =============================================================================
# NOTE: For simulation-specific settings, use .env.simulation file
# The settings below are available but should generally be configured separately

# Enable simulation mode (default: false)
# SIMULATION_MODE=false

# Simulation storage paths
# SIMULATION_STORAGE_PATH=/tmp/pcesdopodappv1_simulation
# SIMULATION_DELTA_PATH=
# SIMULATION_FIXTURES_DIR=

# Simulation behavior
# SIMULATION_ALLOW_LOCALHOST=true       # Allow localhost URLs (default: true)
# SIMULATION_TRUNCATE_TABLES=false      # Truncate Delta tables on start (default: false)
# SIMULATION_DELTA_WRITE_MODE=append    # Delta write mode: append or overwrite

# Simulation file server
# SKIP_EMBEDDED_FILE_SERVER=false       # Skip embedded file server (default: false)
# EXTERNAL_FILE_SERVER_URL=             # Use external file server URL

# Simulation failure injection (for testing resilience)
# CLAIMX_API_FAILURE_RATE=0.0           # API failure rate 0.0-1.0
# CLAIMX_API_FAILURE_DURATION_SEC=0     # Failure duration in seconds
# CLAIMX_API_FAILURE_STATUS=500         # Simulated HTTP status code
# FAILURE_RATE=0.0                      # File server failure rate 0.0-1.0
# FAILURE_DURATION_SEC=0                # File server failure duration
# FAILURE_STATUS=500                    # File server failure status code

# =============================================================================
# PLUGINS - ITEL CABINET API
# =============================================================================
ITEL_DELTA_FORMS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_itel_forms
ITEL_DELTA_ATTACHMENTS_TABLE=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Tables/dbo/claimx_itel_attachments
ITEL_ATTACHMENTS_PATH=abfss://00000000-0000-0000-0000-000000000000@onelake.dfs.fabric.microsoft.com/00000000-0000-0000-0000-000000000000/Files/veriskPipeline/itel_cabinet_form/attachments

# =============================================================================
# Email service configuration
#==============================================================================
EMAIL_SERVICE_BASE_URL=https://your-email-service.com/api
EMAIL_SERVICE_API_KEY=your-api-key