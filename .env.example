# Kafka Pipeline Environment Configuration
# Copy this file to .env and fill in your values
# DO NOT commit the .env file - it contains sensitive credentials

# =============================================================================
# AZURE ONELAKE / FABRIC
# =============================================================================
# Azure OneLake workspace and lakehouse identifiers
AZURE_WORKSPACE_ID=your-workspace-id
AZURE_LAKEHOUSE_ID=your-lakehouse-id

# OneLake base path template
# Format: abfss://{AZURE_WORKSPACE_ID}@onelake.dfs.fabric.microsoft.com/{AZURE_LAKEHOUSE_ID}/Files/veriskPipeline
ONELAKE_BASE_PATH=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Files/veriskPipeline

# =============================================================================
# EVENTHOUSE
# =============================================================================
# Eventhouse cluster URL (shared across domains)
EVENTHOUSE_CLUSTER_URL=https://your-cluster.z8.kusto.fabric.microsoft.com

# ClaimX Eventhouse settings
CLAIMX_EVENTHOUSE_DATABASE=your_claimx_database
CLAIMX_EVENTHOUSE_SOURCE_TABLE=your_claimx_events_table

# XACT Eventhouse settings
XACT_EVENTHOUSE_DATABASE=your_xact_database
XACT_EVENTHOUSE_SOURCE_TABLE=your_xact_events_table

# =============================================================================
# DELTA LAKE TABLE PATHS - CLAIMX
# =============================================================================
# Format: abfss://{WORKSPACE_ID}@onelake.dfs.fabric.microsoft.com/{LAKEHOUSE_ID}/Tables/dbo/{table_name}
CLAIMX_DELTA_EVENTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_events
CLAIMX_DELTA_INVENTORY_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_attachments
CLAIMX_DELTA_PROJECTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_projects
CLAIMX_DELTA_CONTACTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_contacts
CLAIMX_DELTA_MEDIA_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_attachments_metadata
CLAIMX_DELTA_TASKS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_tasks
CLAIMX_DELTA_TASK_TEMPLATES_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_task_templates
CLAIMX_DELTA_EXTERNAL_LINKS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_external_link
CLAIMX_DELTA_VIDEO_COLLAB_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_video_collab

# =============================================================================
# DELTA LAKE TABLE PATHS - XACT
# =============================================================================
XACT_DELTA_EVENTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/xact_events
XACT_DELTA_INVENTORY_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/xact_attachments

# =============================================================================
# DELTA LAKE TABLE PATHS - ITEL CABINET
# =============================================================================
ITEL_DELTA_FORMS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_itel_forms
ITEL_DELTA_ATTACHMENTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_itel_attachments

# =============================================================================
# KAFKA CONNECTION
# =============================================================================
# Kafka broker addresses (comma-separated host:port)
KAFKA_BOOTSTRAP_SERVERS=localhost:9094

# Security protocol: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
KAFKA_SECURITY_PROTOCOL=PLAINTEXT

# SASL mechanism: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER
KAFKA_SASL_MECHANISM=OAUTHBEARER

# SASL credentials (if needed)
KAFKA_SASL_USERNAME=
KAFKA_SASL_PASSWORD=

# =============================================================================
# CLAIMX API
# =============================================================================
# ClaimX API credentials
CLAIMX_API_USERNAME=your-username
CLAIMX_API_PASSWORD=your-password
CLAIMX_API_TOKEN=Basic your-base64-token

# =============================================================================
# AZURE AUTHENTICATION
# =============================================================================
# For OAuth/SPN authentication to Azure services (OneLake, Eventhouse)
AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-service-principal-client-id
AZURE_CLIENT_SECRET=your-service-principal-secret

# =============================================================================
# LOCAL DEVELOPMENT
# =============================================================================
# Local cache directory for downloaded files
CACHE_DIR=/tmp/kafka_pipeline_cache

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Health check settings
HEALTH_ENABLED=true
HEALTH_HOST=127.0.0.1
HEALTH_PORT=8080

# =============================================================================
# OBSERVABILITY
# =============================================================================
# Metrics port for Prometheus scraping
METRICS_PORT=8000

# Enable JSON structured logging
JSON_LOGS=true

# Log upload settings
LOG_UPLOAD_ENABLED=true
LOG_UPLOAD_INTERVAL_CYCLES=10
LOG_RETENTION_DAYS=7

# =============================================================================
# OPENTELEMETRY (DISTRIBUTED TRACING)
# =============================================================================
# Deployment environment (development, staging, production)
# Used to tag traces and metrics
ENVIRONMENT=development

# Jaeger OTLP endpoint for distributed traces
# Default: http://localhost:4317 (starts Jaeger with docker-compose.jaeger.yml)
JAEGER_ENDPOINT=http://localhost:4317

# OpenTelemetry sampling configuration
# always_on = 100% sampling (all traces captured)
# always_off = no sampling (tracing disabled)
# traceidratio = percentage-based sampling (e.g., 0.1 = 10%)
OTEL_TRACES_SAMPLER=always_on

# Service name (automatically set by workers based on domain/worker type)
# Format: {domain}-{worker-name}
# Examples: xact-download-worker, claimx-enrichment-worker
# OTEL_SERVICE_NAME=vpipe-worker

# =============================================================================
# WORKER CONFIGURATION
# =============================================================================
# Download worker settings
DOWNLOAD_CONCURRENCY=10
DOWNLOAD_BATCH_SIZE=20
DOWNLOAD_TIMEOUT_SECONDS=60

# Upload worker settings
UPLOAD_CONCURRENCY=10
UPLOAD_BATCH_SIZE=20

# =============================================================================
# RETRY CONFIGURATION
# =============================================================================
# Comma-separated retry delays in seconds
RETRY_DELAYS=300,600,1200,2400
MAX_RETRIES=4

# =============================================================================
# NOTES
# =============================================================================
# 1. Copy this file to .env and fill in your actual values
# 2. Never commit the .env file to version control
# 3. The .env file is automatically loaded by the application
# 4. Environment variables override config file values
# 5. Use quotes for values with spaces or special characters
