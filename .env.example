# Kafka Pipeline Environment Configuration
# Copy this file to .env and fill in your values
# DO NOT commit the .env file - it contains sensitive credentials

# =============================================================================
# AZURE ONELAKE / FABRIC
# =============================================================================
# Azure OneLake workspace and lakehouse identifiers
AZURE_WORKSPACE_ID=your-workspace-id
AZURE_LAKEHOUSE_ID=your-lakehouse-id

# OneLake base path template
# Format: abfss://{AZURE_WORKSPACE_ID}@onelake.dfs.fabric.microsoft.com/{AZURE_LAKEHOUSE_ID}/Files/veriskPipeline
ONELAKE_BASE_PATH=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Files/veriskPipeline

# =============================================================================
# EVENTHOUSE
# =============================================================================
# Eventhouse cluster URL (shared across domains)
EVENTHOUSE_CLUSTER_URL=https://your-cluster.z8.kusto.fabric.microsoft.com

# ClaimX Eventhouse settings
CLAIMX_EVENTHOUSE_DATABASE=your_claimx_database
CLAIMX_EVENTHOUSE_SOURCE_TABLE=your_claimx_events_table

# XACT Eventhouse settings
XACT_EVENTHOUSE_DATABASE=your_xact_database
XACT_EVENTHOUSE_SOURCE_TABLE=your_xact_events_table

# =============================================================================
# DELTA LAKE TABLE PATHS - CLAIMX
# =============================================================================
# Format: abfss://{WORKSPACE_ID}@onelake.dfs.fabric.microsoft.com/{LAKEHOUSE_ID}/Tables/dbo/{table_name}
CLAIMX_DELTA_EVENTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_events
CLAIMX_DELTA_INVENTORY_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_attachments
CLAIMX_DELTA_PROJECTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_projects
CLAIMX_DELTA_CONTACTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_contacts
CLAIMX_DELTA_MEDIA_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_attachments_metadata
CLAIMX_DELTA_TASKS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_tasks
CLAIMX_DELTA_TASK_TEMPLATES_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_task_templates
CLAIMX_DELTA_EXTERNAL_LINKS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_external_link
CLAIMX_DELTA_VIDEO_COLLAB_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_video_collab

# =============================================================================
# DELTA LAKE TABLE PATHS - XACT
# =============================================================================
XACT_DELTA_EVENTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/xact_events
XACT_DELTA_INVENTORY_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/xact_attachments

# =============================================================================
# DELTA LAKE TABLE PATHS - ITEL CABINET
# =============================================================================
ITEL_DELTA_FORMS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_itel_forms
ITEL_DELTA_ATTACHMENTS_TABLE=abfss://your-workspace-id@onelake.dfs.fabric.microsoft.com/your-lakehouse-id/Tables/dbo/claimx_itel_attachments

# =============================================================================
# KAFKA CONNECTION
# =============================================================================
# Kafka broker addresses (comma-separated host:port)
# Use 'kafka:9092' when running workers in Docker containers (docker-compose)
# Use 'localhost:9094' when running workers directly on host machine
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# Security protocol: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
KAFKA_SECURITY_PROTOCOL=PLAINTEXT

# SASL mechanism: PLAIN, SCRAM-SHA-256, SCRAM-SHA-512, OAUTHBEARER
KAFKA_SASL_MECHANISM=OAUTHBEARER

# SASL credentials (if needed)
KAFKA_SASL_USERNAME=
KAFKA_SASL_PASSWORD=

# =============================================================================
# CLAIMX API
# =============================================================================
# ClaimX API credentials
CLAIMX_API_USERNAME=your-username
CLAIMX_API_PASSWORD=your-password
CLAIMX_API_TOKEN=Basic your-base64-token

# ClaimX API Rate Limiting (optional - prevents hitting API rate limits)
# Enable rate limiting to control throughput to ClaimX API
CLAIMX_API_RATE_LIMIT_ENABLED=false
# Maximum requests per second to ClaimX API (default: 10)
CLAIMX_API_RATE_LIMIT_PER_SECOND=10

# =============================================================================
# AZURE AUTHENTICATION
# =============================================================================
# For OAuth/SPN authentication to Azure services (OneLake, Eventhouse)
AZURE_TENANT_ID=your-tenant-id
AZURE_CLIENT_ID=your-service-principal-client-id
AZURE_CLIENT_SECRET=your-service-principal-secret

# =============================================================================
# PROXY CONFIGURATION (for Docker/corporate environments)
# =============================================================================
# HTTP proxy for outbound connections (required in Docker when behind corporate proxy)
# Format: http://proxy-host:port or http://user:pass@proxy-host:port
#
# Priority order for Eventhouse/Kusto connections:
#   1. EVENTHOUSE_PROXY_URL (most specific, recommended for Kusto)
#   2. HTTPS_PROXY (standard env var)
#   3. HTTP_PROXY (fallback)
#
# These must be set BEFORE the container starts so Azure SDK and Kusto SDK
# can use them for authentication metadata requests.

# Eventhouse-specific proxy (recommended for Kusto/Fabric connections)
# EVENTHOUSE_PROXY_URL=http://your-proxy:8080

# Standard proxy environment variables (used by most HTTP libraries)
# HTTP_PROXY=http://your-proxy:8080
# HTTPS_PROXY=http://your-proxy:8080

# SSL certificate verification (set to "false" for corporate proxy SSL interception)
# Corporate proxies often do SSL inspection, presenting their own certificate.
# If you see "SSL certificate problem: self-signed certificate in certificate chain"
# errors, set this to false to disable SSL verification.
# EVENTHOUSE_SSL_VERIFY=false

# To get your Windows system proxy, run: ./get-proxy.ps1

# =============================================================================
# LOCAL DEVELOPMENT
# =============================================================================
# Local cache directory for downloaded files
CACHE_DIR=/tmp/kafka_pipeline_cache

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Health check settings
HEALTH_ENABLED=true
HEALTH_HOST=127.0.0.1
HEALTH_PORT=8080

# =============================================================================
# OBSERVABILITY
# =============================================================================
# Metrics port for Prometheus scraping
METRICS_PORT=8000

# Enable JSON structured logging
JSON_LOGS=true

# Log upload settings
LOG_UPLOAD_ENABLED=true
LOG_UPLOAD_INTERVAL_CYCLES=10
LOG_RETENTION_DAYS=7

# =============================================================================
# OPENTRACING (DISTRIBUTED TRACING)
# =============================================================================
# Deployment environment (development, staging, production)
# Used to tag traces and metrics
ENVIRONMENT=development

# Jaeger endpoint for distributed traces
# Default: http://localhost:4317 (starts Jaeger with docker-compose.jaeger.yml)
JAEGER_ENDPOINT=http://localhost:4317

# OpenTracing sampling configuration
# always_on = 100% sampling (all traces captured)
# always_off = no sampling (tracing disabled)
# traceidratio = percentage-based sampling (e.g., 0.1 = 10%)
OPENTRACING_TRACES_SAMPLER=always_on

# Service name (automatically set by workers based on domain/worker type)
# Format: {domain}-{worker-name}
# Examples: xact-download-worker, claimx-enrichment-worker
# OPENTRACING_SERVICE_NAME=vpipe-worker

# =============================================================================
# WORKER CONFIGURATION
# =============================================================================
# Download worker settings
DOWNLOAD_CONCURRENCY=10
DOWNLOAD_BATCH_SIZE=20
DOWNLOAD_TIMEOUT_SECONDS=60

# External download rate limiting (optional - for throttling external file downloads)
# Enable rate limiting for external downloads to be respectful to third-party servers
EXTERNAL_DOWNLOAD_RATE_LIMIT_ENABLED=false
# Maximum downloads per second from external sources (default: 5)
EXTERNAL_DOWNLOAD_RATE_LIMIT_PER_SECOND=5

# Upload worker settings
UPLOAD_CONCURRENCY=10
UPLOAD_BATCH_SIZE=20

# =============================================================================
# RETRY CONFIGURATION
# =============================================================================
# Comma-separated retry delays in seconds
RETRY_DELAYS=300,600,1200,2400
MAX_RETRIES=4

# =============================================================================
# NOTES
# =============================================================================
# 1. Copy this file to .env and fill in your actual values
# 2. Never commit the .env file to version control
# 3. The .env file is automatically loaded by the application
# 4. Environment variables override config file values
# 5. Use quotes for values with spaces or special characters
