# Production docker-compose for Kafka Pipeline
#
# Usage:
#   # With local Kafka (for testing)
#   docker-compose --profile kafka up -d
#
#   # Without Kafka (using external Event Hub/Kafka)
#   docker-compose up -d
#
#   # Scale specific workers
#   docker-compose up -d --scale xact-download=5 --scale xact-upload=3

version: '3.8'

services:
  # =============================================================================
  # KAFKA INFRASTRUCTURE (Optional - use profile)
  # =============================================================================

  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka-pipeline-local
    profiles:
      - kafka
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      # KRaft mode (no Zookeeper)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # Listeners Configuration
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,EXTERNAL://localhost:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Topic settings
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_NUM_PARTITIONS: 8
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      # Performance tuning
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_MESSAGE_MAX_BYTES: 10485760
      KAFKA_REPLICA_FETCH_MAX_BYTES: 10485760
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  kafka-init:
    image: apache/kafka:3.7.0
    profiles:
      - kafka
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        echo "Creating Kafka topics..."
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.downloads.pending --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.downloads.cached --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.downloads.results --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.downloads.dlq --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.events.raw --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.enrichment.pending --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic xact.retry --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic delta-events.dlq --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.events.raw --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.enrichment.pending --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.downloads.pending --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.downloads.cached --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.downloads.results --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.downloads.dlq --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.retry --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.entities.rows --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.entities.rows.dlq --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic itel.cabinet.task.tracking --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic itel.cabinet.task.tracking.success --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic itel.cabinet.task.tracking.errors --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic itel.cabinet.api.success --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic itel.cabinet.api.errors --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic itel.cabinet.completed --partitions 5 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.mitigation.task.tracking --partitions 8 --replication-factor 1
        /opt/kafka/bin/kafka-topics.sh --create --if-not-exists --bootstrap-server kafka:9092 --topic claimx.mitigation.task.success --partitions 5 --replication-factor 1
        echo "Topics created successfully:"
        /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:9092

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    profiles:
      - kafka
      - ui
    ports:
      - "8080:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:9092
    depends_on:
      kafka:
        condition: service_healthy

  # =============================================================================
  # XACT WORKERS
  # =============================================================================

  xact-poller:
    build:
      context: .
      dockerfile: Dockerfile
    image: kafka-pipeline:latest
    container_name: xact-poller
    command: ["--worker", "xact-poller"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  xact-event-ingester:
    image: kafka-pipeline:latest
    container_name: xact-event-ingester
    command: ["--worker", "xact-event-ingester"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      replicas: 2

  xact-enricher:
    image: kafka-pipeline:latest
    container_name: xact-enricher
    command: ["--worker", "xact-enricher"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  xact-download:
    image: kafka-pipeline:latest
    command: ["--worker", "xact-download"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      replicas: 4  # Scale this worker - handles heavy I/O
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  xact-upload:
    image: kafka-pipeline:latest
    command: ["--worker", "xact-upload"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      replicas: 4  # Scale this worker - handles heavy I/O
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  xact-result-processor:
    image: kafka-pipeline:latest
    container_name: xact-result-processor
    command: ["--worker", "xact-result-processor"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  xact-delta-writer:
    image: kafka-pipeline:latest
    container_name: xact-delta-writer
    command: ["--worker", "xact-delta-writer"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
      replicas: 2

  xact-retry-scheduler:
    image: kafka-pipeline:latest
    container_name: xact-retry-scheduler
    command: ["--worker", "xact-retry-scheduler"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # =============================================================================
  # CLAIMX WORKERS
  # =============================================================================

  claimx-poller:
    image: kafka-pipeline:latest
    container_name: claimx-poller
    command: ["--worker", "claimx-poller"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  claimx-ingester:
    image: kafka-pipeline:latest
    container_name: claimx-ingester
    command: ["--worker", "claimx-ingester"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      replicas: 4

  claimx-enricher:
    image: kafka-pipeline:latest
    container_name: claimx-enricher
    command: ["--worker", "claimx-enricher"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
      replicas: 3

  claimx-downloader:
    image: kafka-pipeline:latest
    command: ["--worker", "claimx-downloader"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      replicas: 4  # Scale this worker - handles heavy I/O
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 256M

  claimx-uploader:
    image: kafka-pipeline:latest
    command: ["--worker", "claimx-uploader"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      replicas: 4  # Scale this worker - handles heavy I/O
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 256M

  claimx-result-processor:
    image: kafka-pipeline:latest
    container_name: claimx-result-processor
    command: ["--worker", "claimx-result-processor"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M
      replicas: 2

  claimx-delta-writer:
    image: kafka-pipeline:latest
    container_name: claimx-delta-writer
    command: ["--worker", "claimx-delta-writer"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
      replicas: 2

  claimx-retry-scheduler:
    image: kafka-pipeline:latest
    container_name: claimx-retry-scheduler
    command: ["--worker", "claimx-retry-scheduler"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  claimx-entity-writer:
    image: kafka-pipeline:latest
    container_name: claimx-entity-writer
    command: ["--worker", "claimx-entity-writer"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M
      replicas: 2

  # =============================================================================
  # PLUGIN WORKERS
  # =============================================================================

  itel-cabinet-tracking:
    image: kafka-pipeline:latest
    container_name: itel-cabinet-tracking
    command: ["python", "-m", "kafka_pipeline.plugins.itel_cabinet_api.itel_cabinet_tracking_worker"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  itel-cabinet-api:
    image: kafka-pipeline:latest
    container_name: itel-cabinet-api
    command: ["python", "-m", "kafka_pipeline.plugins.itel_cabinet_api.itel_cabinet_api_worker"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  claimx-mitigation-tracking:
    image: kafka-pipeline:latest
    container_name: claimx-mitigation-tracking
    command: ["python", "-m", "kafka_pipeline.plugins.claimx_mitigation_task.mitigation_tracking_worker"]
    env_file:
    volumes:
      - ./logs:/app/logs
      - .env
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # =============================================================================
  # OPTIONAL: METRICS/MONITORING
  # =============================================================================

  # Uncomment if you want to run metrics server
  # metrics:
  #   image: kafka-pipeline:latest
  #   container_name: kafka-pipeline-metrics
  #   command: ["--metrics-port", "8000"]
  #   env_file:
    volumes:
      - ./logs:/app/logs
  #     - .env
  #   ports:
  #     - "8000:8000"
  #   restart: unless-stopped

volumes:
  kafka_data:

networks:
  default:
    name: kafka_pipeline_network
