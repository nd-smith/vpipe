# iTel Cabinet Plugin Refactor - Complete

## What Was Done

Completely refactored the iTel Cabinet plugin from an over-abstracted handler framework to explicit, traceable code.

## Before vs After

### Before (Handler Framework):
- âŒ **400+ line YAML config** defining handler pipelines
- âŒ **String-based handler instantiation** via `create_handler_from_config()`
- âŒ **Generic handlers** (TransformHandler, ValidationHandler, LookupHandler, etc.)
- âŒ **Wrapper handlers** (ConditionalCompletedHandler wrapping other handlers)
- âŒ **Opaque context passing** through `EnrichmentContext.data`
- âŒ **Stack traces** showed generic framework code, not business logic
- âŒ **Hard to debug** - had to trace through YAML â†’ dynamic imports â†’ handler base classes
- âŒ **Mixed logging** - some handlers used core logging, some didn't

### After (Explicit Code):
- âœ… **80 line YAML config** - just Kafka topics and table names
- âœ… **Explicit imports** - `from .pipeline import ItelCabinetPipeline`
- âœ… **Specific classes** - `ItelCabinetPipeline`, `TaskEvent`, `CabinetSubmission`
- âœ… **Simple conditionals** - `if event.task_status == 'COMPLETED'`
- âœ… **Clear data flow** - typed dataclasses with explicit field access
- âœ… **Stack traces** show actual method names: `_enrich_completed_task()`
- âœ… **Easy to debug** - set breakpoint in `pipeline.process()` and step through
- âœ… **Consistent logging** - all code uses core logging infrastructure

## New File Structure

```
kafka_pipeline/plugins/itel_cabinet_api/
â”œâ”€â”€ models.py                           # NEW - Typed data structures
â”œâ”€â”€ parsers.py                          # NEW - Form parsing functions
â”œâ”€â”€ pipeline.py                         # NEW - Main processing logic
â”œâ”€â”€ delta.py                            # NEW - Delta writer wrapper
â”œâ”€â”€ itel_cabinet_tracking_worker.py     # REWRITTEN - Explicit worker
â”œâ”€â”€ itel_cabinet_api_worker.py          # REWRITTEN - Simplified API worker
â””â”€â”€ handlers/                           # DELETED - Old framework files
    â”œâ”€â”€ form_parser.py                  # âŒ Removed
    â”œâ”€â”€ form_transformer.py             # âŒ Removed
    â”œâ”€â”€ conditional_completed.py        # âŒ Removed
    â”œâ”€â”€ completed_publisher.py          # âŒ Removed
    â”œâ”€â”€ dual_table_writer.py            # âŒ Removed
    â”œâ”€â”€ itel_api_sender.py              # âŒ Removed
    â””â”€â”€ media_downloader.py             # âŒ Removed
```

## New Architecture

### Tracking Worker Flow:
```python
# Read pipeline.py:process() to understand the ENTIRE flow
async def process(self, raw_message: dict) -> ProcessedTask:
    # 1. Parse and validate
    event = TaskEvent.from_kafka_message(raw_message)
    self._validate_event(event)

    # 2. Conditionally enrich (COMPLETED only)
    if event.task_status == 'COMPLETED':
        submission, attachments = await self._enrich_completed_task(event)
    else:
        submission, attachments = None, []

    # 3. Write to Delta (always)
    await self._write_to_delta(event, submission, attachments)

    # 4. Publish to API worker (COMPLETED only)
    if event.task_status == 'COMPLETED' and submission:
        await self._publish_for_api(event, submission, attachments)

    return ProcessedTask(event, submission, attachments)
```

### API Worker Flow:
```python
# Read itel_cabinet_api_worker.py:run() to understand the flow
async def run(self):
    async for message in self.consumer:
        # 1. Transform to iTel API format
        api_payload = self._transform_to_api_format(message.value)

        # 2. Send to API (or write to file in test mode)
        if self.api_config.get('test_mode'):
            await self._write_test_payload(api_payload)
        else:
            await self._send_to_api(api_payload)

        # 3. Commit
        await self.consumer.commit()
```

## Key Benefits

### 1. **Traceability**
- **Before**: Error in pipeline â†’ stack trace shows `EnrichmentHandler.enrich()` â†’ no idea which handler
- **After**: Error in pipeline â†’ stack trace shows `ItelCabinetPipeline._enrich_completed_task()` â†’ exact line

### 2. **Debuggability**
- **Before**: Set breakpoint â†’ step through framework code â†’ get lost in abstraction
- **After**: Set breakpoint in `pipeline.process()` â†’ read code top-to-bottom â†’ understand flow

### 3. **Maintainability**
- **Before**: Change flow â†’ update YAML â†’ hope dynamic imports work â†’ debug at runtime
- **After**: Change flow â†’ edit `pipeline.py` â†’ IDE shows errors â†’ fix before running

### 4. **Type Safety**
- **Before**: `context.data` dict â†’ no autocomplete â†’ runtime KeyError
- **After**: `TaskEvent` dataclass â†’ IDE autocomplete â†’ catch errors at write-time

### 5. **Onboarding**
- **Before**: New dev needs to understand: YAML syntax, handler framework, EnrichmentPipeline, context passing, dynamic imports
- **After**: New dev reads `pipeline.py` - it's just Python functions and classes

## Configuration Simplified

### Before (workers.yaml):
```yaml
enrichment_handlers:
  - type: transform
    config:
      mappings:
        event_id: event_id
        event_type: event_type
        # ... 30+ field mappings
  - type: validation
    config:
      required_fields: [...]
      field_rules: {...}
  - type: kafka_pipeline.plugins.itel_cabinet_api.handlers.conditional_completed:ConditionalCompletedHandler
    config:
      wrapped_handler:
        type: lookup
        config: {...}
  # ... 7 more handler configurations
```

### After (workers.yaml):
```yaml
itel_cabinet_tracking:
  kafka:
    input_topic: itel.cabinet.task.tracking
    consumer_group: itel_cabinet_tracking_group
  delta_tables:
    submissions: claimx_itel_forms
    attachments: claimx_itel_attachments
  pipeline:
    claimx_connection: claimx_api
    output_topic: itel.cabinet.completed
    download_media: false
```

**400+ lines â†’ 80 lines**

## Running the Workers

### Tracking Worker:
```bash
python -m kafka_pipeline.plugins.itel_cabinet_api.itel_cabinet_tracking_worker
```

### API Worker (Production):
```bash
python -m kafka_pipeline.plugins.itel_cabinet_api.itel_cabinet_api_worker
```

### API Worker (Dev Mode - writes to files):
```bash
python -m kafka_pipeline.plugins.itel_cabinet_api.itel_cabinet_api_worker --dev
```

## What Happens When Things Break

### Before:
```
ERROR: EnrichmentHandler failed
Stack trace:
  enrichment.py:123 in execute
  base.py:45 in enrich

Where did it fail? What handler? What data?
Good luck finding out! ğŸ¤·
```

### After:
```
ERROR: Failed to enrich completed task
Stack trace:
  pipeline.py:145 in _enrich_completed_task
  parsers.py:67 in parse_cabinet_form

Assignment ID: 12345
Task ID: 32513
Missing field: customer_first_name

Jump to definition â†’ see exact code â†’ fix it âœ…
```

## Lessons Learned

1. **Explicit > Generic**: `ItelCabinetPipeline` is better than `GenericEnrichmentPipeline`
2. **Functions > Frameworks**: `parse_cabinet_form()` is better than `TransformHandler(config)`
3. **Code > YAML**: Python business logic is better than YAML configuration
4. **Types > Dicts**: `TaskEvent` dataclass is better than `dict[str, Any]`
5. **Simple > Flexible**: Hardcoded flow is better than dynamic handler chains

## Future Plugins

When you need to add a new plugin (e.g., photo tasks, inspection reports):

### Don't:
- âŒ Try to reuse `EnrichmentPipeline` framework
- âŒ Create generic `TransformHandler` configurations
- âŒ Define behavior in YAML

### Do:
- âœ… Create `PhotoTaskPipeline` class with explicit `process()` method
- âœ… Write focused functions: `parse_photo_metadata()`, `validate_photo_task()`
- âœ… Define business logic in Python code
- âœ… Copy the iTel Cabinet plugin structure as a template

## Migration Notes

**The old enrichment handler framework still exists** in `kafka_pipeline/plugins/shared/enrichment.py`.

It's used by other parts of the system (ClaimX workers, Xact workers). We only removed it from the iTel Cabinet plugin.

If you want to refactor those too, follow the same pattern:
1. Create explicit pipeline classes
2. Move logic from handlers to focused functions
3. Simplify configuration
4. Remove handler dependencies

---

**Bottom line**: You can now understand, debug, and maintain the iTel Cabinet plugin without a PhD in abstraction theory. ğŸ‰
